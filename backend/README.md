# Backend â€“ PySpark Code Explainer (FastAPI)

This service exposes a clean API endpoint that accepts PySpark code, forwards it to a Gemini model, and returns a structured explanation.

---

## ğŸ“Œ Features
- FastAPI server (`/explain/pyspark`)
- Gemini 1.5 Flash/Pro integration
- Pydantic validation
- Clean modular structure
- Fully dockerized

---

## ğŸ“ File Structure

```text
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py        # App entrypoint
â”‚   â”œâ”€â”€ routes.py      # API routes
â”‚   â”œâ”€â”€ llm.py         # Gemini client
â”‚   â””â”€â”€ schemas.py     # Pydantic models
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## â–¶ï¸ Running (Docker)

From project root:

```bash
docker compose up --build
```

Backend runs internally at:  
`http://backend:8005`

(External port depends on your docker-compose mapping.)

---

## ğŸ” Environment Variables

Create `.env` in `/backend`:

```bash
GEMINI_API_KEY=your_key_here
```

---

## ğŸ“¡ API Endpoint

### POST `/explain/pyspark`

**Request**
```json
{
  "code": "df = spark.read.csv('data.csv')"
}
```

**Response**
```json
{
  "explanation": "This code reads a CSV file into a Spark DataFrame..."
}
```

---

## ğŸ›  Tech
- FastAPI  
- Pydantic  
- Google Generative AI SDK  
- Uvicorn  

---

## ğŸ“ˆ Next Backend Milestones
- Redis caching  
- Queue worker  
- DAG extraction  
- Error-type system  
